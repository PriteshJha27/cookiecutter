import torch
from torch.utils.data import DataLoader
import dask.array as da
from ..preprocessing.image_processor import ImagePreprocessor
from ...utils.logger import get_logger

logger = get_logger(__name__)

class DataManager:
    def __init__(self, config):
        self.config = config
        self.preprocessor = ImagePreprocessor(config)
        
    def create_data_loaders(self, processed_img, labels):
        """Create train, validation and test dataloaders"""
        total_len = len(labels)
        
        # Calculate split sizes
        train_size = int(total_len * self.config['data']['splits']['train'])
        val_size = int(total_len * self.config['data']['splits']['val'])
        
        # Split indices
        indices = list(range(total_len))
        train_indices = indices[:train_size]
        val_indices = indices[train_size:train_size + val_size]
        test_indices = indices[train_size + val_size:]
        
        # Create datasets
        from ..datasets.image_dataset import CustomImageDataset
        
        train_dataset = CustomImageDataset(
            processed_img[train_indices], 
            [labels[i] for i in train_indices]
        )
        
        val_dataset = CustomImageDataset(
            processed_img[val_indices], 
            [labels[i] for i in val_indices]
        )
        
        test_dataset = CustomImageDataset(
            processed_img[test_indices], 
            [labels[i] for i in test_indices]
        )
        
        # Create dataloaders
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config['data']['batch_size'],
            shuffle=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['data']['batch_size'],
            shuffle=False
        )
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config['data']['batch_size'],
            shuffle=False
        )
        
        logger.info(f"Created dataloaders - Train: {len(train_loader.dataset)}, "
                   f"Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}")
        
        return train_loader, val_loader, test_loader
